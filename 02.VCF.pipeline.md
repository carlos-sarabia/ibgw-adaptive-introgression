# VCF pipeline

This is a simple pipeline to filter out VCF variants as in Sarabia et al. (2024), "Potential adaptive introgression from dogs in Iberian gray wolves (Canis lupus)"

#### 1) HaplotypeCaller. We run it per individual (example: dog.belgian_sheepdog.SAMN08872844)

```
gatk=/path_to_GATK/GenomeAnalysisTK.jar
TEMP=/path_to_temp
REF=/path_to_reference/autosomes.lpictus.edited.fasta
INBAM=/path_to_bam/dog.belgian_sheepdog.SAMN08872844/autoXMTY
OUT=/path_to_VCF/a.HaplotypeCaller
BED=/path_to_BED/chromosome.coordinates

for i in {01..38}; do echo chr$i;
java -XX:ParallelGCThreads=14 -Djava.io.tmpdir=$TEMP -Xmx48G -jar $gatk -T HaplotypeCaller -nct 16 \
	-R $REF \
	-I $OUT/dog.belgian_sheepdog.SAMN08872844.chr$i.bam \
	-o $OUT2/dog.belgian_sheepdog.SAMN08872844.chr$i.g.vcf.gz \
	-L $BED/chr$i.coordinates.bed \
	-ERC GVCF
done

for i in {01..38}; do tabix $OUT/dog.belgian_sheepdog.SAMN08872844.chr$i.g.vcf.gz; done
```

#### step b. CombineGVCFs. We run it per chromosome (example: chr01)

```
OUT2=/path_to_VCF/b.CombineGVCF

java -XX:ParallelGCThreads=16 -Djava.io.tmpdir=$TEMP -Xmx48G -jar $gatk -T CombineGVCFs \
	-R $REF \
	--variant $OUT/dog.belgian_sheepdog.SAMN08872844.chr01.g.vcf.gz \
	--variant $OUT/dog.berger_blanc_suisse.SAMEA4506887.chr01.g.vcf.gz \
	...
	-o $OUT2/dataset.ibgw.chr01.vcf \
	-L $BED 
```


#### step c. GenotypeGVCFs. 
```
OUT3=/path_to_VCF/c.GenotypeGVCF

#I will do GATK for chr01 as a test today. Will call GVCF too. 
java -XX:ParallelGCThreads=16 -Djava.io.tmpdir=$TEMP -Xmx48G -jar $gatk -T GenotypeGVCFs \
	-R $REF \
	--variant $OUT2/dataset.ibgw.chr01.vcf \
	-o $OUT3/genotyped.ibgw.chr01.g.vcf \
	-L $BED 
```

#### step d. Concatenation. 
```
bcft=/path_to_bcftools
filelist=/path_to_lists
OUT4=/path_to_VCF/d.BCFtools.concat

$bcft/bcftools concat -f $filelist/ibgw.list -O z -o $OUT4/ibgw.concat.vcf.gz --thread 22
```

#### step e. Filter low complexity regions (tandem repetitions, etc)
```
bedt=/path_to_programs/bedtools
bcft=/path_to_programs/bcftools
vcft=/path_to_programs/vcftools

lowcomp=/path_to_lowcomplexity_regions/CanFam3.1.lowcompregions.autosomes.bed
cpg=/path_to_CPG_islands_regions/canFam3.CpGcoordinates.autosomes.sorted.bed
genic=/path_to_genic_regions/autosomes.10kb.neutral_regions.corrected.bed

path=/path_to_VCFs/17.VCF/genomewide

# header subtraction
head=$(zcat $vcf/d.BCFTOOLs.concat/ibgw.concat.vcf.gz | grep '^#')

# subtraction of low complexity regions
$bedt subtract -a $vcf/d.BCFTOOLs.concat/ibgw.concat.vcf.gz -b $lowcomp | uniq | cat $head - > $vcf/e.Lowcomplexity/ibgw.lowcomp.vcf

# sorting lowcomp.vcf
$bcft sort $vcf/e.Lowcomplexity/ibgw.lowcomp.vcf -o $vcf/e.Lowcomplexity/ibgw.lowcomp.sort.vcf.gz -O z
```

#### f. Select Variants, use only SNPs and filter out non biallelic
```
java -XX:ParallelGCThreads=16 -Djava.io.tmpdir=$TEMP -Xmx48G -jar $gatk -T SelectVariants \
        -selectType SNP \
        -restrictAllelesTo BIALLELIC \
        -R $REF \
        --variant:VCF $vcf/e.Lowcomplexity/ibgw.lowcomp.sort.vcf.gz \
        -o $vcf/f.SelectVariants/ibgw.selectvar.vcf
```

#### g. Extract variants fixed in all genomes. 

```
# This step is necessary only if using VCF for non-fixed variants. This is interesting in statistics like iHS and nSL, which would not work in variants with allele frequencies > 80% (Voight et al 2006 PlosONE; Ferrer-Admetlla et al. 2014 MBE). 
# Huber et al. 2016, Mol Ecol presents evidence that, for composite likelihood ratio (CLR) statistics such as SweepFinder, using a dataset with polymorphic sites and fixed variants at 100% (AF=1.00) (CLR2) would work better than datasets with only polymorphic sites (CLR1) and polymorphic sites, fixed variants at 0% and fixed variants at 100% (CLR3). Based on this, we can filter to our preference. 
# Since we are using selscan to filter out low minimum allele frequency variants, we will work with CLR2.

$bcft view -e 'INFO/AF=1.00' $vcf/f.SelectVariants/ibgw.selectvar.vcf > $vcf/g.Fixedvariants/ibgw.fixedvar.CLR1.vcf

mv $vcf/f.SelectVariants/ibgw.selectvar.vcf $vcf/g.Fixedvariants/ibgw.fixedvar.CLR2.vcf
```

#### h.Filter out per RankSum, etc - Recommended filter by GATK best practices (https://gatk.broadinstitute.org/hc/en-us/sections/360007226651-Best-Practices-Workflows)
```
java -XX:ParallelGCThreads=16 -Djava.io.tmpdir=$TEMP -Xmx48G -jar $gatk -T VariantFiltration \
	--filterExpression "QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0" \
	-R $REF \
	--filterName "h.hardfilter" \
	-V $vcf/g.Fixedvariants/ibgw.fixedvar.CLR2.vcf \
	-o $vcf/h.Hardfilters/ibgw.hard.snps.CLR2.vcf

# creating bed file of sites with 
grep "h.hardfilter" $vcf/h.Hardfilters/ibgw.hard.snps.CLR2.vcf | awk '{print$1"\t"$2"\t"$2}' | grep "chr" > $vcf/h.Hardfilters/ibgw.h.hard.CLR2.bed

# subtracting sites that did not pass the best practice filters
$bedt subtract -a $vcf/h.Hardfilters/ibgw.hard.snps.CLR2.vcf -b $vcf/h.Hardfilters/ibgw.h.hard.CLR2.bed > $vcf/h.Hardfilters/ibgw.hard.snps.filtered.CLR2.vcf

# header subtraction
head=$(grep '^#' $vcf/h.Hardfilters/ibgw.hard.snps.CLR2.vcf)

cat $head $vcf/h.Hardfilters/ibgw.hard.snps.CLR2.vcf | gzip - > $vcf/h.Hardfilters/ibgw.hard.snps.headed.CLR2.vcf.gz
```

#### i.Filter CpG islands
```
# subtracting CpG islands
$bedt subtract -a $vcf/h.Hardfilters/ibgw.hard.snps.headed.CLR2.vcf -b $cpg > $vcf/i.CpG.islands/ibgw.CpGfilt.CLR2.vcf
```

#### j. Filter out missing variants. We filter for variants absent in this dataset.
```
# We will apply a first "soft" filter where we filter out variants missing at the whole dataset

$bcft filter -e "F_MISSING = 1" -Ov $vcf/i.CpG.islands/ibgw.CpGfilt.CLR2.vcf > $vcf/j.Missingvariants/ibgw.soft.CLR2.vcf

# We can also apply a "hard" filter where we filter out variants missing at least once in the whole dataset
$bcft filter -e "N_MISSING >= 1" -Ov $vcf/i.CpG.islands/ibgw.CpGfilt.CLR2.vcf > $vcf/j.Missingvariants/ibgw.hard.CLR2.vcf
```

#### k.Filter out per low depth. We can worry later about higher depths.
```
$bcft filter -e "FORMAT/DP < 3" $vcf/j.Missingvariants/ibgw.hard.CLR2.vcf > $vcf/k.Depthfiltering/ibgw.hard.min.filtered.CLR2.vcf

# step k 2. Filter out per high depth. We will need to plot the mean depth distribution before doing this. Later we will filter out per genotype quality and/or genic regions (if needed).
# There is a good tutorial of how to do so at https://speciationgenomics.github.io/filtering_vcfs/. We extracted the mean depth of coverage per individual and per each site with vcftools. 

$vcft --vcf $vcf/k.Depthfiltering/ibgw.hard.min.filtered.CLR2.vcf --site-mean-depth --out $vcf/k.Depthfiltering/ibgw.hard.min.filtered.CLR2.persite

$bcft filter -e "FORMAT/DP > 25" $vcf/k.Depthfiltering/ibgw.hard.min.filtered.CLR2.vcf > $vcf/k.Depthfiltering/ibgw.hard.minmax.filtered.CLR2.vcf
```

#### l. Filter GQ<20. We will not eliminate those SNPs with GQ<20 but will substitute those failing the filter for a missing site "./."
```
$bcft filter -e "FORMAT/GQ < 20" -S . $vcf/k.Depthfiltering/ibgw.hard.minmax.filtered.CLR2.vcf > $vcf/l.GQfilter/ibgw.hard.minmax.filtered.CLR2.GQ.20.unfilt.vcf
```


#### m. Phase the genomes. 
```
beag=/path_to_beagle/beagle4.1
in=/path/l.GQfilter/ibgw
out=/path_to_selscan_input/0.input.phased

java -XX:ParallelGCThreads=16 -Djava.io.tmpdir=/scratch/gpfs/csarabia/coyote.mexico -Xmx16g -Xss5m -jar $beag/beagle.11Mar19.69c.jar gt=$in/ibgw.hard.minmax.filtered.CLR2.GQ.20.unfilt.vcf out=$in/ibgw.hard.CLR2.GQ.20.unfilt.ext.phased nthreads=20 niterations=100 
```
